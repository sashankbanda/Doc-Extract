import json
import logging
import os
from typing import Any, Dict, List, Optional, Union

import litellm

from backend.config import config
from backend.services.semantic_tagger import semantic_tagger


logger = logging.getLogger(__name__)

LineMeta = Union[List[Any], Dict[str, Any]]

# Mapping dictionary: canonical_name -> list of synonyms
CANONICAL_MAPPINGS: Dict[str, List[str]] = {
    "lob": [
        "Line of Business", "Line of Insurance", "LOB", "Coverage Code", 
        "Policy Type", "Claim type", "Loss Type", "File Type"
    ],
    "insured": [
        "Insured", "Insured Name", "Insured(s)", "Account Name", "Assured Name", 
        "Named Insured", "Policy Holder", "Location", "Insured Group", "Policy name", 
        "Client/Account", "Client", "Consumer", "Client Name"
    ],
    "dba": [
        "Facility", "Insured Facility", "Insured DBA", "Account Name", 
        "Location Address", "Insured Name", "Org", "Org1"
    ],
    "policyNumber": [
        "Policy Number", "Policy No", "Policy Reference", "Policy #", "Policy Num", 
        "Policy", "Insured Policy Num", "Certificate Num", "Policy-Asco-Mod",
        "Contract Number", "POLICY INQUIRY", "Policy Nbr", "Lead Policy", "Policy Identifier"
    ],
    "effdate": [
        "Policy Effective", "Policy Term", "Cov Eff Date", "Term", "Inceptiion Date", 
        "Period", "Eff Date", "Policy year", "Policy Effective Date Range", "UW Year", 
        "Date(s) Insured", "Contract Period", "Date Contract Effective", 
        "Contract Effective Date", "POL DATE", "Incept", "Coverage Dates", 
        "Term Totals for", "Original Risk Inception Date", "Policy Period Desc", 
        "Losses from", "Cov Eff Date"
    ],
    "expdate": [
        "Policy Expiry", "Policy Term", "Cov Exp Date", "Term", "Exp Date", "Period", 
        "Policy Expiration Date", "Expiry Date", "Period", "Policy Effective Date Range", 
        "Policy Period", "Policy Termination Date", "Policy End Date", "Cov Exp Date"
    ],
    "carrier": [
        "Carrier", "Insurer Name", "Insurance Company", "Writing company", "Broker Name"
    ],
    "valuedDate": [
        "Data", "Valued", "Financial", "Report date", "Valuation Date", "Run Date", 
        "Generated Date", "Data reported", "Loss Run", "Report Executed", 
        "Evaluation Date", "Selected Source Process Date", "Losses Last Updated",
        "Loss Run External", "Transaction Date", "PolicyValuedDate", 
        "Report Date / Time", "Generated by Looker on", "Report Generated", "Prepared", 
        "Report Run Date", "Print date", "Date Produced", "Report print date", "Created", 
        "REPORT RUN"
    ],
    "claimNumber": [
        "Claim No", "Claim", "Claim #", "Claim Reference #", "Claim Num", 
        "Claim Master Reference", "Claim occurrence", "Case #", "Casefile",
        "Claim Number", "Claim Nbr", "File Number", "File #", "Loss Number", 
        "Reference Number", "Matter Number", "Our Reference"
    ],
    "claimant": [
        "Claimant", "Claimant Name", "Claimants", "Injured Employee", "Worker's Name", 
        "Payee", "Employee", "Clmt Name", "Drvr/Clmt Name", 
        "CLAIMANT/DRIVER/LOCATION OF PROPERTY", "Party Name", "IW Name", "PATIENT NAME"
    ],
    "claimStatus": [
        "Status", "Claim Status", "Sts", "Loss Status", "Open or Closed", "O/C", 
        "Clm Stat Desc", "Feature Status", "Open/Closed Flag", "s"
    ],
    "closedDate": [
        "Claim Closed Date", "Closed Date", "Date Closed", "Closed Dt", "ClosedDate",
        "Date Clm Closed", "Close", "Month Closed", "Last Closed Date", "LL Close Date", 
        "Close Date / Reopened Date"
    ],
    "reportedDate": [
        "Claim Date", "Claim Report Date", "Claim Made Date", "Date Received", 
        "Date Rcvd", "Report", "Report Date", "Date Reported", "Reported Date",
        "Date Rep to Insured", "Administrative Notified Date", "Date Incident Reported", 
        "Run Date", "Claim Reported Date", "Date Reported to Carrier", 
        "Reported to Program", "Date Rptd", "Claimant Report Date", "Notice Date", 
        "Notification Date"
    ],
    "dateOfLoss": [
        "Loss Date", "Accident Date", "Injury Date", "Event Date", "Incident Date", 
        "DOL", "DCM", "Inj. Date", "Claim Date", "Notice of Loss", "D/L", 
        "Occurrence Date", "Acc Date", "Loss Incurred Date"
    ],
    "lossDescription": [
        "Desc", "Description", "Loss Description", "Incident / Accident Description", 
        "Injury Description", "Event Description", "Event Detail", "Claim Description", 
        "Incident Description", "Cause Cd Desc", "Loss type", "Injury Detail", 
        "Injury Source", "Cause Of Loss", "ClaimLossNarrative", "Facts", 
        "Case Description", "Loss Reason", "ASL Desc"
    ],
    "lossLocation": [
        "Loss Location", "Location/MD", "Location Name", "Location Address",
        "ACCIDENT LOCATION", "Accident State", "Location/Site", "Loss Loc", 
        "Location Level", "Incident Location"
    ],
    "state": [
        "ST", "State", "Claim Location", "Loss State", "Jurisdiction", "Venue State", 
        "Accident State", "LossStateCd", "State/Province of Loss", "Loss Province", 
        "Loss Loc-State", "Incident State"
    ],
    "city": [
        "Loss City", "City", "Loss Loc-City", "Plant Div"
    ],
    "medicalPaid": [
        "Medical Paid", "Paid Medical", "Med Pd", "Medical Payments", "Pd Med", 
        "MED PAY", "Gross Medical Paid", "Medical/BI (USD) Paid", "Paid-To-Date MED", 
        "Medical PTD", "MTD Payments", "MedicalPayments", "MED Paid", "MED. PAID", "Paid"
    ],
    "medicalReserves": [
        "Medical Reserves", "Medical (O/S Reserves)", "O/S Medical", "Med Res", 
        "Medical Outstanding", "MedicalReserves", "Fut Res Med", "Outstanding Med", 
        "Open Medical Reserves", "Medical/BI (USD) Outstanding", "Medical O/R", 
        "Medical Outstanding Rsvs", "Med O/S Rsvs", "Medical O", 
        "Reserve Amount (Medical)", "Avail Medical", "Medical Res", "Outstanding Med", 
        "Open Medical Reserves", "Medical Reserve", "MED Reserve", "Outstanding1", 
        "MED. RESV", "Reserve"
    ],
    "indemnityPaid": [
        "Indemnity Paid", "Indemnity (Paid to Date)", "Paid Indemnity", 
        "Indem Payments", "Paid Loss", "Loss Paid", "Total Loss Paid", "Paid Ind", 
        "Loss PTD", "CMP Paid", "Comp/PD (USD) Paid", "ITD Indemnity Payment", 
        "Paid-To-Date IND", "Settlement Paid", "TOTAL FOR CLAIM Indemnity Paid", 
        "Loss Paid (FGU)", "Comp PTD", "WKDIS PAID", "ITD Payments", "Loss/ Ind (PD)", 
        "Indemnity(Net Payments)", "Paid Indemnity BI/Med", "Ind Pd", "IndemnityPayments", 
        "Paid Ind", "Gross Indemnity Paid", "Gross Paid Loss", "Payments-Indemnity Paid", 
        "Comp Paid", "Compensation Paid", "Loss Paid To Date", "PAID LOSSES", 
        "Indem Paid", "Paid"
    ],
    "indemnityReserves": [
        "Indemnity Reserves", "Indemnity (O/S Reserves)", "O/S Indemnity", 
        "Indemnity Outstanding", "Indem Reserves", "Fut Res Ind", 
        "Outstanding Reserves Loss", "Loss Reserve", "Total Loss Reserve", 
        "RESERVE LOSSES", "O/S Loss Rsv", "IND Reserve", "CMP Reserve", 
        "Comp/PD (USD) Outstanding", "Case Loss Reserve", 
        "ITD Indemnity Reserve Balance", "OPEN LOSSES", "Reserve IND", 
        "Loss Reserved (FGU)", "Comp Outstanding Rsv", "Compensation Reserve", 
        "WKDIS RESV", "Avail Indemnity", "Ind Out", "Indemnity Res", "Ind Res", 
        "IndemnityReserves", "Outstanding Ind", "Open Indemnity Reserves", 
        "Indemnity Reserve", "Pending Ind", "CMP Reserve", "Outstanding", 
        "Reserves-Indemnity", "Indemnity O/R", "Comp Reserve", "Loss Reserve Amt", 
        "Indem Reserve", "Reserves Indemnity"
    ],
    "expensesPaid": [
        "Expenses Paid", "Expense Paid", "Paid Legal/Expense", "Exp Pd", 
        "Gross Defense Paid", "Defence (Paid)", "Loss Adj. Expense Paid", 
        "LAE Payments", "Pd Exp/Oth", "Defense PTD", "Paid ALAE", "Expense PTD", 
        "ALE Paid", "Alloc Exp Paid", "Defense Paid (FGU)", "Expenses (Paid)", "PD Exp",
        "ExpensePayments", "Paid Expense", "Gross Paid Expense", "Paid LAE", 
        "Total Expense Paid", "ALAE Paid", "Payments-Other Expenses", 
        "Expense Paid To Date", "ALE Paid"
    ],
    "expensesReserves": [
        "Expenses Reserves", "ALAE Reserves", "Outstanding Expense", 
        "O/S Legal/Expense", "Expense Outstanding", "Defence(Outstanding)", 
        "Loss Adj. Expense Outstanding", "LAE Reserves", "Expense Reserve", 
        "Fut Res Exp", "LAE Reserves", "O/S Defense Reserve", 
        "Outstanding Expense Reserves", "ALE Reserve", "O/S Exp Reserve", 
        "Expenses (USD) Outstanding", "Case ALAE Reserve", "Expense Res", "Exp Res", 
        "ExpenseReserves", "Outstanding Exp", "Expense Reserve", "Pending LAE", 
        "ALAE Reserve", "Reserves-Other Expenses", "Expense O/R", 
        "Expense Outstanding", "EXPENSE RESV", "Avail Legal", "Expense Reserve Amt", 
        "OPEN EXPENSE", "Reserves Expense"
    ],
    "totalPaid": [
        "Total Paid", "Paid", "Tot Paid", "Total Payments", "Gross Paid to Date", 
        "Total Claims Paid", "Paid Amount"
    ],
    "totalReserve": [
        "Total Reserve", "Reserves", "Reserved", "Outstanding reserve", 
        "Total Outstanding", "Gross Outstanding", "Gross Reserve", 
        "Remaining reserve", "Reserve (Total Incurred Details)", "Total Open", 
        "O/S Reserve", "Total Claims Outstanding", "Total Out", "Total Res", 
        "Total Outstanding Reserves", "Reserve Amount"
    ],
    "totalIndemnity": [
        "Total Indemnity", "Pd Ind", "Incurred Ind", "INDEMNITY", "COMP INC", 
        "Total Loss paid", "Indemnity Paid"
    ],
    "totalExpenses": [
        "Total Expenses", "Expense", "Pd Exp/Oth", "LAE Incurred", "Net Expense", 
        "Total Expense Paid", "Total Defense", "Total Expense", "Net Expense", 
        "Defense Paid"
    ],
    "totalIncurredSource": [
        "Total Incurred", "Total Incurred Source", "Total (Total Incurred)", 
        "Total Inc", "Total", "Incurred (Total)", "Grand Total Incurred", "Incurred", 
        "TOTAL INCURRED AMOUNT", "TOTALS Incurred", "Gross Incurred", 
        "Incurred Total(Gross)", "TOTAL CLAIM", "Amount Paid", "Totals(USD) Incurred", 
        "Total Case Incurred Before Recoveries", "Incur Total", "Total Incr", 
        "Case Incurred Loss", "Paid Loss", "TotalPaid", "PaidTotal", 
        "Tot (Gross incurred)", "Total I", "Casefile Totals (Incurred)", 
        "Total Claims Incurred", "Total Incurred Amount", "Net Total Inc", 
        "Total Incurred excluding Recovery (Total)", "Claim Total Incurred", "Paid"
    ],
    "recoveries": [
        "Recoveries", "Total Recoveries", "TotalRecoveries", "Tot Recov", "Recovery", 
        "Recovered", "Recovery Incurred", "Incurred Recovery", 
        "Recoveries Impacting Incurred (Incurred)", "Recoveries Impacting Incurred", 
        "Recovery (USD) Incurred", "Deductible  / Recovery", "TotRcvry", 
        "Deductible Recovered", "Applied Recovery", "Tot (Recoveries)", 
        "Paid Deductible", "RECOVERED", "Subro Salvage Recovered", "ITD Recoveries", 
        "Recovery/Refund (Total)", "Inc. Recovery", "Total Recov", "Total Recovery", 
        "Reserves-Recovery Reserves", "Payments-Recovery Received", "Recovery Total", 
        "RECOVERY PENDING"
    ],
}

# Reverse mapping: synonym -> canonical_name (for fast lookup)
SYNONYM_TO_CANONICAL: Dict[str, str] = {}
for canonical_name, synonyms in CANONICAL_MAPPINGS.items():
    for synonym in synonyms:
        # Normalize synonym for matching (case-insensitive, strip whitespace)
        normalized = synonym.strip().lower()
        SYNONYM_TO_CANONICAL[normalized] = canonical_name


def find_canonical_name(source_key: str) -> Optional[str]:
    """
    Find the canonical name for a given source key by matching against synonyms.
    
    Args:
        source_key: The original key as it appears in the document
        
    Returns:
        Canonical name if a match is found, None otherwise
    """
    if not source_key or source_key == "(no key)":
        return None
    
    # Normalize the source key for matching
    normalized = source_key.strip().lower()
    
    # Try exact match first
    if normalized in SYNONYM_TO_CANONICAL:
        return SYNONYM_TO_CANONICAL[normalized]
    
    # Try substring matching (check if any synonym is contained in the key or vice versa)
    for synonym, canonical in SYNONYM_TO_CANONICAL.items():
        if synonym in normalized or normalized in synonym:
            return canonical
    
    return None


class LLMService:
    """
    Handles LLM-powered extraction of raw fields from documents.
    
    The LLM only extracts raw fields with line numbers. All normalization,
    grouping, and highlight generation is handled by backend services.
    """

    def __init__(self) -> None:
        # Ensure the Groq key is available to LiteLLM.
        os.environ.setdefault("GROQ_API_KEY", config.GROQ_API_KEY)
        self.model = "groq/llama-3.3-70b-versatile"
        self.system_prompt = self._build_system_prompt()

    def _build_system_prompt(self) -> str:
        """
        Build system prompt that instructs LLM to extract a flat array of items with line numbers.
        No normalization, grouping, structure inference, or coordinate math - just raw extraction.
        """
        # Build mapping synonyms section for the prompt
        mapping_section = "**Field Mapping Synonyms (for reference):**\n\n"
        mapping_section += "The following mappings help identify canonical field names. Use the exact source key as it appears in the document.\n\n"
        for canonical_name, synonyms in CANONICAL_MAPPINGS.items():
            mapping_section += f"- `{canonical_name}`: {', '.join(synonyms[:5])}"  # Show first 5 synonyms
            if len(synonyms) > 5:
                mapping_section += f", ... (and {len(synonyms) - 5} more)"
            mapping_section += "\n"
        mapping_section += "\n"
        
        return (
            "You are an expert insurance document extraction AI. Your goal is to extract **ALL** visible data from the Loss Run Report.\n\n"
            "**CRITICAL: Your role is ONLY to extract raw fields exactly as seen in the document.**\n\n"
            "**STRICT RULES - YOU MUST FOLLOW THESE:**\n\n"
            "1. Extract EVERY visible field/value from the document\n"
            "2. Do NOT normalize keys (use exact labels as they appear)\n"
            "3. Do NOT group claims or create nested structure\n"
            "4. Do NOT invent structure or infer relationships\n"
            "5. Do NOT skip columns or summarize data\n"
            "6. Do NOT infer missing values\n"
            "7. Do NOT guess line numbers - if unclear, skip the item\n\n"
            + mapping_section +
            "**Line Number References:**\n\n"
            "- The raw text contains line numbers in square brackets (e.g., [15], [0x11])\n"
            "- For each field, list ALL line numbers where that field's value appears\n"
            "- Line numbers must match the [NN] markers in the text EXACTLY\n"
            "- Multi-line values → include all line numbers (e.g., [15, 16, 17])\n"
            "- If line numbers are unclear or missing → skip the item (do NOT guess)\n\n"
            "**Output JSON Structure (MANDATORY):**\n\n"
            "Return valid JSON with this EXACT structure:\n"
            "{\n"
            '  "items": [\n'
            "    {\n"
            '      "source_key": "Claimant Name",\n'
            '      "value": "SYDIA",\n'
            '      "line_numbers": [15, 16, 17]\n'
            "    },\n"
            "    {\n"
            '      "source_key": "Claim Number",\n'
            '      "value": "12345",\n'
            '      "line_numbers": [12]\n'
            "    }\n"
            "  ]\n"
            "}\n\n"
            "**Requirements:**\n\n"
            "- `items` is an array\n"
            "- One object per extracted value\n"
            "- `source_key` = exact label as it appears in document (use the original field name as seen)\n"
            "- `value` = exact value as it appears (no transformation)\n"
            "- `line_numbers` = array of integers matching [NN] markers exactly\n"
            "- If a value exists, it MUST have line_numbers\n"
            "- If line_numbers are unclear → skip the item (do NOT guess)\n"
            "- Keep strictly to JSON. Do not add comments or extra keys.\n"
            "- If a field is not present, omit it (do not include null values)."
        )

    async def structure_document(
        self, raw_text: str, line_metadata: Union[List[LineMeta], Dict[str, LineMeta]]
    ) -> Dict[str, Any]:
        """
        Extract flat items array from document using LLM.
        
        Returns simple structure:
        {
            "items": [
                {
                    "source_key": "Claimant Name",
                    "canonical_name": "claimant",
                    "value": "SYDIA",
                    "line_numbers": [15, 16, 17],
                    "semantic_type": "claim.claimant"
                },
                ...
            ]
        }
        
        No normalization, grouping, or complex logic - just raw extraction with line numbers.
        """
        # Call LLM to extract items
        messages = [
            {"role": "system", "content": self.system_prompt},
            {
                "role": "user",
                "content": (
                    "Extract data from the following document text. "
                    "Text includes line numbers in square brackets like [12] or [0x11]. "
                    "List the line numbers for each field in the 'line_numbers' array.\n\n"
                    f"{raw_text}"
                ),
            },
        ]

        response = await litellm.acompletion(
            model=self.model,
            messages=messages,
            response_format={"type": "json_object"},
        )
        content = response["choices"][0]["message"]["content"]

        try:
            parsed = json.loads(content)
        except json.JSONDecodeError:
            # If the model returns leading/trailing text, try to salvage JSON payload.
            start = content.find("{")
            end = content.rfind("}")
            if start != -1 and end != -1 and end > start:
                parsed = json.loads(content[start : end + 1])
            else:
                raise

        # Extract items from LLM response
        raw_items = parsed.get("items", [])
        if not raw_items:
            logger.warning("[LLMService] No items found in LLM response")
            raw_items = []

        # Convert and validate items: normalize line_numbers format
        items = []
        invalid_items = []
        
        for item in raw_items:
            # Support both "key" (old format) and "source_key" (new format) for backward compatibility
            source_key = item.get("source_key", item.get("key", "")).strip()
            value = item.get("value", "")
            if value is not None:
                value = str(value).strip()
            else:
                value = ""
            line_numbers_raw = item.get("line_numbers", [])
            
            # PRESERVE ALL ITEMS - even with empty keys/values (data loss prevention)
            # Use empty string for missing keys/values instead of skipping
            
            # Convert line numbers to integers (handles hex, strings, etc.)
            line_numbers = []
            for line_val in line_numbers_raw:
                converted = self._convert_line_number(line_val)
                if converted is not None:
                    line_numbers.append(converted)
            
            # If no valid line numbers, use empty array (preserve item, just no line refs)
            # This ensures no data loss - item is still included
            
            # Find canonical name from mapping
            canonical_name = find_canonical_name(source_key) if source_key else None
            
            # Add item (preserved even if key/value/line_numbers are empty)
            items.append({
                "source_key": source_key if source_key else "(no key)",
                "canonical_name": canonical_name,
                "value": value if value else "(no value)",
                "line_numbers": sorted(list(set(line_numbers))) if line_numbers else []  # Deduplicate and sort
            })
        
        # No items are skipped - all items are preserved (data loss prevention)
        logger.info(f"[LLMService] Extracted {len(items)} items (all preserved, no data loss)")
        
        # Add semantic_type tags to all items (deterministic, dictionary-based)
        tagged_items = semantic_tagger.tag_items(items)
        
        # Return flat, lossless structure - no grouping, no claims, no sections
        return {
            "items": tagged_items
        }

    def _convert_line_number(self, line_val: Any) -> Optional[int]:
        """
        Convert a line number to an integer, handling hex strings and other formats.
        
        Handles:
        - Integers: returns as-is
        - Hex strings: "2A" -> 42, "0x2A" -> 42
        - Float integers: 2.0 -> 2
        - String integers: "42" -> 42
        
        Returns None if conversion fails.
        """
        if isinstance(line_val, int):
            return line_val if line_val >= 0 else None
        
        if isinstance(line_val, float):
            # Check if it's effectively an integer
            if line_val.is_integer() and line_val >= 0:
                return int(line_val)
            return None
        
        if isinstance(line_val, str):
            line_str = line_val.strip()
            # Try hex format (with or without 0x prefix)
            if line_str.startswith("0x") or line_str.startswith("0X"):
                try:
                    return int(line_str, 16)
                except ValueError:
                    pass
            # Try hex without prefix (e.g., "2A", "2C")
            try:
                # Check if it looks like hex (contains A-F)
                if any(c in line_str.upper() for c in "ABCDEF"):
                    return int(line_str, 16)
            except ValueError:
                pass
            # Try regular integer
            try:
                val = int(line_str)
                return val if val >= 0 else None
            except ValueError:
                pass
        
        return None



llm_service = LLMService()


